"""
# 1 åˆ†ç±»ä¸å›å½’

from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor
# x=[[0,2,3],[1,3,4],[3,5,6],[4,7,8],[2,3,4]]
# y=[0,0,1,1,0]
x=[[0,1,2],[1,2,3],[2,3,4],[3,4,5]]
y=[0.1,0.2,0.3,0.4]

# model=KNeighborsClassifier(n_neighbors=3)
model=KNeighborsRegressor(n_neighbors=3)
model.fit(x,y)
print(model.predict([[4,4,5]]))

====================================================================================================
"""

"""
# 2 å½’ä¸€åŒ–é¢„å¤„ç†
from sklearn.preprocessing import MinMaxScaler,StandardScaler
x=[[90,2,10,40],[60,4,15,45],[75,3,13,46]]

# å½’ä¸€åŒ– é€šè¿‡å¯¹åŸå§‹æ•°æ®è¿›è¡Œå˜æ¢æŠŠæ•°æ®æ˜ å°„åˆ°ã€mi,mxã€‘(é»˜è®¤ä¸º[0,1])ä¹‹é—´
process=MinMaxScaler()
data=process.fit_transform(x)
print(data)

# æ ‡å‡†åŒ– é€šè¿‡å¯¹åŸå§‹æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–ï¼Œè½¬æ¢ä¸ºå‡å€¼ä¸º0æ ‡å‡†å·®ä¸º1çš„æ ‡å‡†æ­£æ€åˆ†å¸ƒçš„æ•°æ®
process=StandardScaler()
data=process.fit_transform(x)
print(data)

print(process.mean_) # æ¯ä¸ªç‰¹å¾çš„å‡å€¼
print(process.var_) # æ¯ä¸ªç‰¹å¾çš„æ–¹å·®
====================================================================================================
"""

"""
# 3 ã€å®æ“ã€‘åˆ©ç”¨KNNç®—æ³•è¿›è¡Œé¸¢å°¾èŠ±åˆ†ç±»

# åŠ è½½å·¥å…·åŒ…
from sklearn.datasets import load_iris

import seaborn as sns
# Seaborn æ˜¯ä¸€ä¸ªåŸºäº Matplotlib çš„ Python æ•°æ®å¯è§†åŒ–åº“ï¼Œä¸“æ³¨äºç»Ÿè®¡æ•°æ®çš„å¯è§†åŒ–ã€‚
# å®ƒé€šè¿‡ç®€åŒ–ç»˜å›¾æµç¨‹ã€ä¼˜åŒ–é»˜è®¤æ ·å¼å’Œæä¾›é«˜çº§æ¥å£ï¼Œå¸®åŠ©ç”¨æˆ·æ›´é«˜æ•ˆåœ°åˆ›å»ºç¾è§‚ä¸”ä¿¡æ¯ä¸°å¯Œçš„ç»Ÿè®¡å›¾è¡¨ã€‚

import matplotlib.pyplot as plt

import pandas as pd
# Pandas æ˜¯ Python ä¸­æœ€æµè¡Œçš„æ•°æ®åˆ†æå’Œå¤„ç†åº“ï¼Œä¸“é—¨è®¾è®¡ç”¨äºé«˜æ•ˆå¤„ç†ç»“æ„åŒ–æ•°æ®ï¼ˆè¡¨æ ¼æ•°æ®ï¼‰ã€‚
# å®ƒæä¾›äº†çµæ´»çš„æ•°æ®ç»“æ„å’Œå·¥å…·ï¼Œä½¿å¾—æ•°æ®æ¸…æ´—ã€è½¬æ¢ã€åˆ†æå’Œå¯è§†åŒ–å˜å¾—ç®€å•é«˜æ•ˆã€‚

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# åŠ è½½æ•°æ®é›†
iris_data = load_iris()
# print(iris_data)
# print(type(iris_data))
# # è¯´å®ƒæ˜¯ä¸€ä¸ªbunchç±» ä½†æˆ‘æ„Ÿè§‰æ›´è´´è¿‘å­—å…¸
# print(iris_data.keys())
# # dataæ˜¯æ¯é¡¹å±æ€§å€¼ targetæ˜¯æ¯é¡¹çš„æ ‡ç­¾
# # feature_namesæ˜¯æ¯é¡¹çš„å±æ€§å target_namesæ˜¯æ¯é¡¹çš„æ ‡ç­¾å
# print(iris_data.feature_names)
# print(iris_data.target_names)
# print(iris_data.data_module)

# pandasæ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºæ•°æ®æŒ–æ˜çš„pythonåº“ï¼Œå®ƒä»¥Numpyä¸ºåŸºç¡€ï¼Œå€ŸåŠ›Numpyæ¨¡å—åœ¨è®¡ç®—æœºæ–¹é¢æ€§èƒ½å¼ºçš„ä¼˜åŠ¿ï¼Œ
# è€Œä¸”åŸºäºmatplotlibï¼Œèƒ½å¤Ÿæ–¹ä¾¿çš„ç”»å›¾ï¼Œè¿˜æ‹¥æœ‰è‡ªå·±ç‹¬ç‰¹çš„æ•°æ®ç»“æ„ï¼Œå¦‚DataFrameå’ŒSeries
iris_df = pd.DataFrame(iris_data['data'],columns=iris_data.feature_names)
# # æŠŠå±æ€§å€¼å’Œå±æ€§åè¯»è¿›iris_df
# print(type(iris_df))
# print(iris_df.keys())

iris_df['label']=iris_data.target
# # å°†æ ‡ç­¾å€¼æ·»åŠ è¿›iris_df
# print(iris_df.keys())

sns.lmplot(x='sepal length (cm)',y='sepal width (cm)',data=iris_df,hue='label')
# ä¸€ä¸ªç©ºæ ¼éƒ½ä¸èƒ½é”™
# é»˜è®¤ä¼šåŒæ—¶æ˜¾ç¤º æ•£ç‚¹å›¾ å’Œ çº¿æ€§å›å½’æ‹Ÿåˆçº¿
# ä¸åŒlabelç±»åˆ«çš„æ•°æ®ä¼šä»¥ä¸åŒé¢œè‰²æ˜¾ç¤º
# è‡ªåŠ¨æ·»åŠ  å›å½’æ–¹ç¨‹ å’Œ ç½®ä¿¡åŒºé—´å¸¦
# plt.show()

# ç‰¹å¾å·¥ç¨‹

# æ•°æ®é›†åˆ’åˆ†ï¼ˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼‰
# xæ˜¯è¾“å…¥yæ˜¯è¾“å‡º
x_train,x_test,y_train,y_test=train_test_split(iris_data.data,iris_data.target,test_size=0.3,random_state=22)
# print(x_train) #105
# print(f"Len of x_train is:{len(x_train)}")
# print(y_train) #105
# print(f"Len of y_train is:{len(y_train)}")
# print(x_test) #45
# print(f"Len of x_test is:{len(x_test)}")
# print(y_test) #45
# print(f"Len of y_test is:{len(y_test)}")

# æ ‡å‡†åŒ–
# ä½¿ç”¨æ­£äº¤æ ‡å‡†åŒ– å®ä¾‹åŒ–ä¸ºä¸€ä¸ªå¯¹è±¡process
process = StandardScaler()
x_train = process.fit_transform(x_train)
# å…ˆç”¨fitè®¡ç®—æ•°æ®çš„ç»Ÿè®¡é‡ï¼ˆå¦‚å‡å€¼ã€æ–¹å·®ï¼‰ï¼Œç„¶åç”¨fitçš„ç»Ÿè®¡é‡é€šè¿‡transformè¿›è¡Œæ ‡å‡†åŒ–è½¬æ¢
# print(x_train)
x_test = process.transform(x_test)
# ç›´æ¥ç”¨ä¸Šé¢çš„fitçš„ç»Ÿè®¡é‡é€šè¿‡transformè¿›è¡Œæ ‡å‡†åŒ–è½¬
# print(x_test)

# è®­ç»ƒæ¨¡å‹
# å®ä¾‹åŒ–KNNæ¨¡å‹ä¸ºmodel
model = KNeighborsClassifier(n_neighbors=3)

# è°ƒç”¨fitæ³•
model.fit(x_train,y_train)
# é€šè¿‡è®­ç»ƒæ•°æ®ï¼ˆç‰¹å¾x_trainå’Œæ ‡ç­¾y_trainï¼‰å­¦ä¹ æ¨¡å‹å‚æ•°ï¼Œå»ºç«‹ç‰¹å¾ä¸ç›®æ ‡å˜é‡ä¹‹é—´çš„æ˜ å°„å…³ç³»
# å¯¹äºKNNåˆ†ç±»å™¨ï¼Œè¯¥è¿‡ç¨‹ä¼šå­˜å‚¨æ‰€æœ‰è®­ç»ƒæ ·æœ¬çš„ç‰¹å¾å‘é‡å’Œæ ‡ç­¾ï¼Œç”¨äºåç»­é¢„æµ‹æ—¶çš„è·ç¦»è®¡ç®—
# å’ŒStandardScaler()ä¸­çš„fitä¸ä¸€æ ·
# é¢„å¤„ç†ä¸­çš„fit()ï¼šä»…è®¡ç®—æ•°æ®çš„ç»Ÿè®¡é‡ï¼ˆå¦‚å‡å€¼ã€æ ‡å‡†å·®ï¼‰ï¼Œä¸æ¶‰åŠæ ‡ç­¾ä¿¡æ¯
# æ¨¡å‹ä¸­çš„fit()ï¼šåŒæ—¶åˆ©ç”¨ç‰¹å¾å’Œæ ‡ç­¾è¿›è¡Œæœ‰ç›‘ç£å­¦ä¹ ï¼Œç”Ÿæˆå†³ç­–è§„åˆ™

# æŠ€æœ¯å®ç°ç‰¹ç‚¹
# KNNç®—æ³•çš„fit()æ–¹æ³•å±äºæƒ°æ€§å­¦ä¹ ï¼ˆlazy learningï¼‰ï¼Œå®é™…ä¸è¿›è¡Œæ˜¾å¼è®¡ç®—ï¼Œä»…ä¿å­˜è®­ç»ƒæ•°æ®é›†ã€‚
# é¢„æµ‹é˜¶æ®µæ‰ä¼šåŠ¨æ€è®¡ç®—æ–°æ ·æœ¬ä¸å­˜å‚¨æ ·æœ¬çš„è·ç¦»ã€‚

# æµç¨‹å¿…è¦æ€§
# è¯¥æ­¥éª¤å¿…é¡»å‡ºç°åœ¨transform()ä¹‹åï¼Œç¡®ä¿æ¨¡å‹æ¥æ”¶çš„æ˜¯ç»è¿‡æ ‡å‡†åŒ–çš„æ•°æ®ï¼Œé¿å…ç‰¹å¾é‡çº²å·®å¼‚å¯¹è·ç¦»è®¡ç®—çš„å½±å“ã€‚
# æ ‡å‡†åŒ–åçš„æ•°æ®èƒ½æå‡KNNç­‰åŸºäºè·ç¦»çš„ç®—æ³•æ€§èƒ½ã€‚


x=[[5.1,3.5,1.4,0.2]]
x=process.transform(x)
# ç›´æ¥ç”¨ä¹‹å‰çš„fitçš„ç»Ÿè®¡é‡é€šè¿‡transformè¿›è¡Œæ ‡å‡†åŒ–è½¬
# print(x)
# print(model.predict_proba(x))
# åˆ¤æ–­xå±äºå„ä¸ªtarget_nameçš„æ¦‚ç‡

# æ¨¡å‹è¯„ä¼°ï¼ˆå‡†ç¡®ç‡ï¼‰
# 6.1 ä½¿ç”¨é¢„æµ‹ç»“æœy_predict
y_predict=model.predict(x_test)
# æ ¹æ®è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹
# print(y_predict)
acc = accuracy_score(y_test,y_predict)
print(acc)

# 6.2 ç›´æ¥ç»™x_testï¼Œy_testæµ‹è¯•æ¨¡å‹å‡†ç¡®æ€§
acc = model.score(x_test,y_test)
print(acc)
====================================================================================================
"""

"""
# 4ã€å®æ“ã€‘ äº¤å‰ç½‘æ ¼éªŒè¯æœç´¢åœ¨é¸¢å°¾èŠ±åˆ†ç±»ä¸­çš„åº”ç”¨
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split,GridSearchCV
# train_test_split æ˜¯ scikit-learn ä¸­çš„ä¸€ä¸ªå‡½æ•°ï¼Œä½œç”¨æ˜¯ï¼š
# æŠŠä¸€ä¸ªå®Œæ•´çš„æ•°æ®é›†åˆ†æˆâ€œè®­ç»ƒé›†â€å’Œâ€œæµ‹è¯•é›†â€ï¼Œé€šå¸¸ç”¨äºæœºå™¨å­¦ä¹ ä¸­çš„æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°ã€‚
# GridSearchCV æ˜¯ scikit-learn ä¸­çš„ä¸€ä¸ªè‡ªåŠ¨è°ƒå‚å·¥å…·ï¼Œç”¨äºåœ¨å¤šä¸ªå‚æ•°ç»„åˆä¸­æ‰¾åˆ°æœ€ä¼˜ç»„åˆã€‚
# Cross Validationï¼Œäº¤å‰éªŒè¯ï¼Œç¡®ä¿ç»“æœå¯é 
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# 1åŠ è½½æ•°æ®
data=load_iris()
# print(type(data))
# print(data.keys())
# print(data.data)
# print(f'\n{data.target}')
# 2æ•°æ®é›†åˆ’åˆ†
x_train,x_test,y_train,y_test=train_test_split(data.data,data.target,test_size=0.2,random_state=22)
# 3ç‰¹å¾é¢„å¤„ç†
pre=StandardScaler()
x_train=pre.fit_transform(x_train)
# 4æ¨¡å‹å®ä¾‹åŒ–+äº¤å‰éªŒè¯+ç½‘æ ¼æœç´¢
model=KNeighborsClassifier(n_neighbors=1)
#åˆ›å»ºä¸€ä¸ªKè¿‘é‚»åˆ†ç±»å™¨ï¼ˆKNNï¼‰
# åˆå§‹è®¾å®šK=1ï¼ˆå³æ¯æ¬¡é¢„æµ‹çœ‹â€œæœ€è¿‘çš„1ä¸ªé‚»å±…â€ï¼‰
# ğŸ§ è¯´æ˜ï¼š
# è™½ç„¶è¿™é‡Œè®¾ç½®äº†n_neighbors=1ï¼Œä½†å…¶å®åé¢ä½ ç”¨ GridSearchCV ä¼šè¦†ç›–è¿™ä¸ªå€¼ï¼Œå®ƒåªæ˜¯åœ¨åˆå§‹åŒ–æ—¶çš„é»˜è®¤å€¼ã€‚
paras_grid={'n_neighbors':[4,5,7,9]}
# åˆ›å»ºäº†ä¸€ä¸ªâ€œå‚æ•°å­—å…¸â€ï¼Œå‘Šè¯‰ GridSearchCV è¦å°è¯•å“ªå‡ ä¸ªå‚æ•°ç»„åˆ(Kå€¼ï¼ˆé‚»å±…ä¸ªæ•°ï¼‰)ã€‚
estimator=GridSearchCV(
    estimator=model,        # ä½ è¦ä¼˜åŒ–çš„åŸºç¡€æ¨¡å‹ï¼ˆKNNï¼‰
    param_grid=paras_grid,  # è¦æœç´¢çš„å‚æ•°èŒƒå›´ï¼ˆä¸Šé¢é‚£å¼ è¡¨ï¼‰
    cv=4)                   # ä½¿ç”¨4æŠ˜äº¤å‰éªŒè¯
# åˆ›å»ºä¸€ä¸ª ç½‘æ ¼æœç´¢ + äº¤å‰éªŒè¯ï¼ˆCrossValidationï¼‰çš„æ¨¡å‹é€‰æ‹©å™¨ï¼Œåå­—å« estimatorã€‚
# å®ƒä¼šåœ¨å‚æ•°èŒƒå›´ {n_neighbors: [4, 5, 7, 9]} ä¸­è¿›è¡Œéå†ï¼Œ
# å¹¶å¯¹æ¯ä¸ªå‚æ•°ä½¿ç”¨ 4æŠ˜äº¤å‰éªŒè¯ï¼Œä»ä¸­æ‰¾å‡ºè¡¨ç°æœ€å¥½çš„é‚£ä¸ªå‚æ•°ã€‚
########################################
# ä»¥ä¸‹è¿‡ç¨‹ä»…å½“ä½ å–‚ç»™å®ƒæ•°æ®åæ‰ä¼šå‘ç”Ÿ
# ï¼ˆåœ¨æœ¬ç¨‹åºä¸­æ˜¯ï¼š
# estimator.fit(x_train,y_train)
# ï¼‰
# æ¯æ¬¡ç”¨ 3 ä¸ªåšè®­ç»ƒï¼Œ1 ä¸ªåšéªŒè¯ï¼Œå…±è¿›è¡Œ 4 æ¬¡è®­ç»ƒ/éªŒè¯ï¼Œç„¶åå–å¹³å‡åˆ†ã€‚
# è®­ç»ƒï¼š1+2+3 â†’ éªŒè¯ï¼š4
# è®­ç»ƒï¼š1+2+4 â†’ éªŒè¯ï¼š3
# è®­ç»ƒï¼š1+3+4 â†’ éªŒè¯ï¼š2
# è®­ç»ƒï¼š2+3+4 â†’ éªŒè¯ï¼š1
# è¿™ä¸ªè¿‡ç¨‹å¯¹ 4ã€5ã€7ã€9 æ¯ä¸ª K å€¼éƒ½æ‰§è¡Œä¸€éã€‚
# æ‰§è¡Œå®Œä¹‹åï¼Œä½ å¯ä»¥è·å¾—ï¼š
# å±æ€§                       å«ä¹‰
# estimator.best_params_    æœ€ä¼˜å‚æ•°ï¼ˆæ¯”å¦‚ï¼š{'n_neighbors': 5}ï¼‰
# estimator.best_score_	    æœ€ä¼˜å‚æ•°å¯¹åº”çš„å¹³å‡äº¤å‰éªŒè¯åˆ†æ•°(æ»¡åˆ†1.0ï¼Œå¯¹åº”100%å‡†ç¡®åº¦)
# estimator.best_estimator_	ç”¨æœ€ä¼˜å‚æ•°è®­ç»ƒå¥½çš„æ¨¡å‹
# estimator.predict(X_test)	ç›´æ¥ç”¨æœ€ä¼˜æ¨¡å‹é¢„æµ‹
########################################
# print(type(estimator))
estimator.fit(x_train,y_train)
# å¼€å§‹æ‰§è¡Œç½‘æ ¼æœç´¢ï¼šç”¨ x_train å’Œ y_train æ•°æ®ï¼Œ
# é’ˆå¯¹æ¯ä¸ª n_neighbors å€¼ï¼Œè¿›è¡Œ 4 æ¬¡äº¤å‰éªŒè¯ï¼Œæœ€åæ‰¾åˆ°æœ€ä¼˜çš„å‚æ•°ï¼Œå¹¶æŠŠæœ€ä¼˜æ¨¡å‹è®­ç»ƒå‡ºæ¥ã€‚

# print(estimator.best_params_)
print(estimator.best_score_)
# print(estimator.best_estimator_) # å‡†ç¡®ç‡0.9666666666666668
# print(estimator.cv_results_) #åŒ…å«æ‰€æœ‰ç»„åˆè®­ç»ƒç»“æœçš„å­—å…¸

model=KNeighborsClassifier(n_neighbors=7)
model.fit(x_train,y_train)
# x=[[5.1,3.5,1.4,0.2]]
# x=pre.transform(x)
y_predict=model.predict(x_test)
print(accuracy_score(y_test,y_predict)) #å‡†ç¡®ç‡0.4666666666666667 è¿œä½äº GridSearchCV
====================================================================================================
"""

"""
#5 ç¼–å†™KNNä»£ç å®ç°æ‰‹å†™æ•°å­—è¯†åˆ«
#ï¼ˆç‰¹å¾é¢„å¤„ç†ï¼Œäº¤å‰éªŒè¯ç½‘æ ¼æœç´¢ï¼‰
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import MinMaxScaler

#è·å–æ•°æ®
data=pd.read_csv("æ‰‹å†™æ•°å­—è¯†åˆ«.csv")
# print(data.keys()) # labelæŒ‡æ ‡ç­¾ï¼Œåˆ†ä¸º0-9 æ€»å…±784ä¸ªåƒç´ ï¼Œå³28*28
# print(min(data['pixel400'])ï¼Œmax(data['pixel400'])) # æ¯ä¸ªåƒç´ çš„ç°åº¦èŒƒå›´ä¸º0-255
x=data.iloc[: , 1:]
# é€‰å–æ‰€æœ‰çš„è¡Œ é€‰å–ä»ä¸‹æ ‡ä¸º1å¼€å§‹æ‰€æœ‰çš„åˆ—
# ilocï¼ˆå…¨ç§°ï¼šinteger-location based indexingï¼‰ æ˜¯ pandas ä¸­ç”¨äºæŒ‰â€œä½ç½®â€é€‰æ‹©æ•°æ®çš„æ–¹æ³•ã€‚

y=data.iloc[: , 0]
# é€‰å–æ‰€æœ‰çš„è¡Œ é€‰å–ä¸‹æ ‡ä¸º0çš„åˆ—

# ç‰¹å¾å½’ä¸€åŒ– ã€æ³¨æ„ã€‘
transform=MinMaxScaler()
# print(type(x))
# print(x.iloc[:,399])
# print(x.iloc[1,399])
# print(x.iloc[1,399]/255) # MinMaxScaler åœ¨è¿™é‡Œç­‰ä»·äº/255

x=transform.fit_transform(x)
# print(type(x))
# print(x[:,399])
# print(x[1,399])

# æ•°æ®é›†åˆ’åˆ†
x_train,x_test,y_train,y_test=train_test_split(x,        #xï¼šç‰¹å¾æ•°æ®ï¼Œå½’ä¸€åŒ–ä¹‹åçš„æ¯å¼ å›¾ç‰‡çš„784ä¸ªåƒç´ å€¼ï¼ˆå·²ç»ç”¨ MinMaxScaler å¤„ç†è¿‡äº†ï¼‰ã€‚
                                               y,               #yï¼šæ ‡ç­¾æ•°æ®ï¼Œä¹Ÿå°±æ˜¯æ¯å¼ å›¾ä»£è¡¨çš„æ•°å­—ï¼ˆ0-9ï¼‰ã€‚
                                               test_size=0.2,   #è¡¨ç¤ºæµ‹è¯•é›†å æ€»æ•°æ®çš„ 20%ï¼Œè®­ç»ƒé›†å  80%ã€‚
                                               stratify=y,      #è¿™æ˜¯ä¸€ä¸ªéå¸¸é‡è¦çš„å‚æ•°ï¼Œè¡¨ç¤ºï¼šæŒ‰åŸå§‹æ ‡ç­¾çš„æ¯”ä¾‹ï¼Œè¿›è¡Œâ€œåˆ†å±‚æŠ½æ ·â€åˆ’åˆ†æ•°æ®ã€‚
                                                                #å¦‚æœä½ ä¸å†™ stratify=yï¼Œç³»ç»Ÿæ˜¯ã€Œå®Œå…¨éšæœºã€é€‰å‡º20%çš„æ•°æ®ä½œä¸ºæµ‹è¯•é›†ï¼Œ
                                                                #æœ‰å¯èƒ½æŸäº›æ ‡ç­¾çš„æ•°é‡éå¸¸å°‘ï¼Œç”šè‡³æ²¡æœ‰ï¼Œå¯¼è‡´æµ‹è¯•ç»“æœä¸å‡†ç¡®ã€‚
                                                                #å†™äº† stratify=y ä¹‹åï¼Œåˆ’åˆ†å‡ºæ¥çš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­ï¼Œ
                                                                #æ¯ä¸ªç±»åˆ«çš„æ¯”ä¾‹ä¼šå’ŒåŸå§‹æ•°æ®ä¸­ä¸€æ ·ï¼Œé¿å…ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ã€‚
                                               random_state=22) #ç”¨äºè®¾ç½®ã€Œéšæœºç§å­ã€ï¼Œè®©ä½ æ¯æ¬¡è¿è¡Œä»£ç æ—¶åˆ’åˆ†å‡ºçš„è®­ç»ƒé›†/æµ‹è¯•é›†æ˜¯ä¸€æ ·çš„ã€‚
#æ¨¡å‹å®ä¾‹åŒ–
model=KNeighborsClassifier(n_neighbors=1)
#ç½‘æ ¼æœç´¢äº¤å‰éªŒè¯
param_grid={'n_neighbors':[3,5,7,9,10,11]}
model=(GridSearchCV             # è¿™æ˜¯ scikit-learn ä¸­çš„ä¸€ä¸ªå‡½æ•°ï¼Œå…¨ç§°æ˜¯ï¼š
                                # Grid Search Cross Validationï¼ˆç½‘æ ¼æœç´¢äº¤å‰éªŒè¯ï¼‰
                                # å®ƒçš„ä½œç”¨æ˜¯ï¼š
                                # åœ¨ä½ è®¾ç½®çš„ä¸€å †â€œå‚æ•°ç»„åˆâ€ä¸­ï¼Œé€šè¿‡äº¤å‰éªŒè¯è‡ªåŠ¨æ‰¾å‡ºæ•ˆæœæœ€å¥½çš„å‚æ•°ç»„åˆï¼Œå¹¶è¿”å›å¯¹åº”çš„æ¨¡å‹ã€‚
       (estimator=model,        # estimator æ˜¯ä½ æƒ³è¦è°ƒå‚çš„æ¨¡å‹ï¼Œå¿…é¡»æ˜¯ä¸€ä¸ªå·²ç»å®ä¾‹åŒ–è¿‡çš„æ¨¡å‹å¯¹è±¡ã€‚
        param_grid=param_grid,  # param_grid æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œä½ è¦æœç´¢çš„å‚æ•°èŒƒå›´ã€‚
        cv=4,                   # è¿™æ˜¯ äº¤å‰éªŒè¯ï¼ˆCross Validationï¼‰ çš„æŠ˜æ•°ï¼Œæ„æ€æ˜¯ï¼š
                                # æ¯ç§å‚æ•°ç»„åˆéƒ½ç”¨4æŠ˜äº¤å‰éªŒè¯æ¥è¯„ä¼°æ€§èƒ½ã€‚
        verbose=2))             #åœ¨è‹±æ–‡ä¸­ï¼šverbose = â€œè¯å¤šçš„â€ï¼Œâ€œå•°å—¦çš„â€
                                # åœ¨ç¼–ç¨‹ä¸­å®ƒçš„æ„æ€æ˜¯ï¼šæ§åˆ¶ç¨‹åºè¿è¡Œè¿‡ç¨‹ä¸­è¦ä¸è¦â€œè¯´è¯â€ï¼Œè¯´å¤šå°‘è¯ã€‚
                                # æ¢å¥è¯è¯´ï¼šverbose å‚æ•°å†³å®šç¨‹åºåœ¨æ‰§è¡Œæ—¶æ˜¯å¦è¾“å‡ºä¸­é—´ä¿¡æ¯ï¼Œæ¯”å¦‚è¿›åº¦ã€ç»†èŠ‚ã€è®­ç»ƒæƒ…å†µç­‰ç­‰ã€‚
                                # 0ï¼ˆé»˜è®¤ï¼‰	å®‰é™æ¨¡å¼	ä»€ä¹ˆéƒ½ä¸è¾“å‡º
                                # 1	        ç®€ç•¥æ¨¡å¼	åªæ˜¾ç¤ºæ¯ä¸€ç»„å‚æ•°çš„æ•´ä½“è®­ç»ƒå¼€å§‹/å®Œæˆ
                                # 2	        è¯¦ç»†æ¨¡å¼	æ˜¾ç¤ºæ¯ä¸€æŠ˜äº¤å‰éªŒè¯çš„è®­ç»ƒæƒ…å†µ
                                # 3 åŠä»¥ä¸Š	è¶…è¯¦ç»†	ä¼šæ˜¾ç¤ºæ›´ç»†ç²’åº¦çš„ä¿¡æ¯ï¼ˆå‡ ä¹ä¸ä¼šç”¨åˆ°ï¼‰

# print(f"type of x_train is {type(x_train)}") # <class 'numpy.ndarray'> å¯ä»¥è¿›è¡Œè®­ç»ƒ
# print(f"type of y_train is {type(y_train)}") # <class 'pandas.core.series.Series'> å¯ä»¥è¿›è¡Œè®­ç»ƒ
model.fit(x_train,y_train)
# print(model.best_estimator_)    # å¾—å‡º3çš„å‡†ç¡®ç‡æœ€é«˜

# æ¨¡å‹è®­ç»ƒ
model=KNeighborsClassifier(n_neighbors=3)
model.fit(x_train,y_train)

# æ¨¡å‹é¢„æµ‹
img=plt.imread('demo.png')
img=img.reshape(1,-1)
# è¿™æ˜¯åœ¨å¯¹å›¾åƒè¿›è¡Œå½¢çŠ¶å˜æ¢ï¼ˆreshapeï¼‰ï¼Œå‡†å¤‡é€å…¥æ¨¡å‹ã€‚
# è§£è¯»ï¼š.reshape(1, -1) è¡¨ç¤ºæŠŠå›¾ç‰‡å˜æˆä¸€ç»´å‘é‡å¹¶åŠ ä¸Šä¸€ä¸ªæ‰¹æ¬¡ç»´åº¦ï¼›
# å‡è®¾åŸå›¾æ˜¯ 28Ã—28ï¼Œå˜æˆ (1, 784)ï¼›
# ä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒç°åœ¨å˜æˆäº†ä¸€ä¸ª 1 è¡Œã€784 åˆ— çš„äºŒç»´æ•°ç»„ï¼Œç¬¦åˆ KNN æ¨¡å‹è¾“å…¥æ ¼å¼ã€‚
img=transform.transform(img) # MinMaxScaler
y_pred=model.predict(img)
print(f"é¢„æµ‹ç»“æœä¸ºï¼š{y_pred[0]}")

# æ¨¡å‹è¯„ä¼°
print(model.score(x_test,y_test))
# ====================================================================================================
"""

"""
#6 Kaggleç«èµ›å®æˆ˜
import pandas as pd
train=pd.read_csv("kaggle/train.csv")#kaggleå‰é¢ä¸èƒ½æœ‰/
x=train.iloc[:,1:]
# print(x)
y=train.iloc[:,0]
# print(y)



from sklearn.preprocessing import MinMaxScaler
transform=MinMaxScaler()
x=transform.fit_transform(x)

from sklearn.neighbors import KNeighborsClassifier
# model=KNeighborsClassifier(n_neighbors=1)
# param_grid={'n_neighbors':[3,5,7,9,10,11]}
# from sklearn.model_selection import GridSearchCV
# model=GridSearchCV(estimator=model,param_grid=param_grid,cv=4,verbose=2)
# model.fit(x,y)
# print(model.best_estimator_)# å¾—å‡º3çš„å‡†ç¡®ç‡æœ€é«˜

model=KNeighborsClassifier(n_neighbors=3)
# print(f"type of x is {type(x)}") # <class 'numpy.ndarray'> å¯ä»¥è¿›è¡Œè®­ç»ƒ
# print(f"type of y is {type(y)}") # <class 'pandas.core.series.Series'> å¯ä»¥è¿›è¡Œè®­ç»ƒ
model.fit(x,y)
print(model.score(x,y))

test=pd.read_csv("kaggle/test.csv")
x_test=test.iloc[:,:]
# print(x_test)
x_test=transform.transform(x_test)
y_predict=model.predict(x_test)

#ç”Ÿæˆsubmissionæ–‡ä»¶
import numpy as np
submission=pd.DataFrame({"ImageId":np.arange(1,len(y_predict)+1),
                         "Label":y_predict})

submission.to_csv("kaggle/submission.csv",
                  index=False)  # index=Falseè¡¨ç¤ºï¼š
                                # ä¸è¦æŠŠ DataFrame çš„è¡Œç´¢å¼•å†™è¿› CSV æ–‡ä»¶ï¼ˆå¦åˆ™ CSV çš„ç¬¬ä¸€åˆ—ä¼šå˜æˆ 0ã€1ã€2ã€3â€¦â€¦ï¼‰
"""